{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('lending_club_loan_two.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loan_repaid'] = df['loan_status'].map({'Fully Paid':1,'Charged Off':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('emp_title',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_co = df[df['loan_status']=='Charged Off'].groupby('emp_length').count()['loan_status']\n",
    "emp_fp = df[df['loan_status']=='Fully Paid'].groupby('emp_length').count()['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('emp_length',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('title',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9998/1719564190.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  total_acc_avg = df.groupby('total_acc').mean()['mort_acc']\n"
     ]
    }
   ],
   "source": [
    "total_acc_avg = df.groupby('total_acc').mean()['mort_acc']\n",
    "\n",
    "# %%\n",
    "# filling out missing values in mort_acc\n",
    "def fill_mort_acc(total_acc,mort_acc):\n",
    "    if np.isnan(mort_acc):\n",
    "        return total_acc_avg[total_acc]\n",
    "    else:\n",
    "        return mort_acc\n",
    "\n",
    "# %%\n",
    "df['mort_acc'] = df.apply(lambda x: fill_mort_acc(x['total_acc'],x['mort_acc']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df[['verification_status','application_type','initial_list_status','purpose']],drop_first=True)\n",
    "df = pd.concat([df.drop(['verification_status','application_type','initial_list_status','purpose'],axis=1),dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['home_ownership'] = df['home_ownership'].replace(['NONE','ANY'],'OTHER')\n",
    "\n",
    "# %%\n",
    "dummies = pd.get_dummies(df['home_ownership'],drop_first=True)\n",
    "df = pd.concat([df.drop(['home_ownership'],axis=1),dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['address'].apply(lambda address:address[-5:])\n",
    "\n",
    "# %%\n",
    "df['zip_code'] = df['address'].apply(lambda address:address[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df['zip_code'],drop_first=True)\n",
    "df = pd.concat([df.drop(['zip_code'],axis=1),dummies],axis=1)\n",
    "\n",
    "# %%\n",
    "df = df.drop('address',axis=1)\n",
    "df = df.drop('issue_d',axis=1)\n",
    "df['earliest_cr_line'] = df['earliest_cr_line'].apply(lambda date: int(date[-4:]))\n",
    "df = df.drop('grade',axis=1)\n",
    "subgrade_dummies = pd.get_dummies(df['sub_grade'],drop_first=True)\n",
    "\n",
    "# %%\n",
    "df = pd.concat([df.drop('sub_grade',axis=1),subgrade_dummies],axis=1)\n",
    "\n",
    "# %%\n",
    "dummies = pd.get_dummies(df['term'],drop_first=True)\n",
    "df = pd.concat([df.drop(['term'],axis=1),dummies],axis=1)\n",
    "\n",
    "# %%\n",
    "dummies = pd.get_dummies(df['loan_status'],drop_first=True)\n",
    "df = pd.concat([df.drop(['loan_status'],axis=1),dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop('loan_repaid',axis=1).values\n",
    "y = df['loan_repaid'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout\n",
    "from tensorflow.keras.constraints import max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 13:41:25.088660: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-16 13:41:25.088761: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-16 13:41:25.088796: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (79f44b6b0317): /proc/driver/nvidia/version does not exist\n",
      "2023-01-16 13:41:25.089264: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb4a0ac80907d7f44e1a5e88d3d3381b33e3dbedd3a24d113e876f30a0c46bee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
